{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88a884a-fe87-4676-9979-c8abe3161adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hyarrava/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    " \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76de2d6-c4ac-49f8-af65-ecf0f6b82380",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85ccc54-40c2-4122-8b8a-8eaa762fbae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/news_summary_more.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a3843c-9384-4b5f-9535-3d06f9c84f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>98401</td>\n",
       "      <td>98401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>98280</td>\n",
       "      <td>98360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Warne produced 'ball of century' with his 1st ...</td>\n",
       "      <td>Virender Sehwag was captaining India when he h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headlines  \\\n",
       "count                                               98401   \n",
       "unique                                              98280   \n",
       "top     Warne produced 'ball of century' with his 1st ...   \n",
       "freq                                                    3   \n",
       "\n",
       "                                                     text  \n",
       "count                                               98401  \n",
       "unique                                              98360  \n",
       "top     Virender Sehwag was captaining India when he h...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260384a0-134a-4d47-8729-714d847a0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98401 entries, 0 to 98400\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   headlines  98401 non-null  object\n",
      " 1   text       98401 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f44cd4-c210-47a1-850f-3d7ba6eb83af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"â\\x82¹95 lakh prize offered for 'radical ideas' to solve weak UK growth\",\n",
       " \"  'Loveratri' is not demeaning towards any culture: Salman\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"headlines\"].max(), data[\"headlines\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3424e9-3665-4ad7-94ba-b073f8ac3661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\"\"(\"â\\x82¹95 lakh prize offered for 'radical ideas' to solve weak UK growth\",\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0863c65-9df6-4e76-a5da-d35e758ffd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ac85f83-9da0-42ff-9fdd-842049c75578",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"headlines_char_count\"] = data[\"headlines\"].apply(lambda x: char_count(x))\n",
    "data[\"text_char_count\"] = data[\"text\"].apply(lambda x: char_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc28a3ec-7c66-463d-9520-3c5c150e2463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 9, 450, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"headlines_char_count\"].max(), data[\"headlines_char_count\"].min(), data[\"text_char_count\"].max(), data[\"text_char_count\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c68b5a6f-b002-408b-be4d-01e3f50d95ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>headlines_char_count</th>\n",
       "      <th>text_char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>headlines</td>\n",
       "      <td>text</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    headlines  text  headlines_char_count  text_char_count\n",
       "52  headlines  text                     9                4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"text_char_count\"]== data[\"text_char_count\"].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25bc4b17-58ec-4282-842b-842ce0c51a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fff8d0e-0c9c-4a0d-9b90-3513cf2ff87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ousted Nissan Chairman Carlos Ghosn has said his arrest over alleged financial misconduct was led by \"plot and treason\" by the Japanese carmaker\\'s executives who opposed its deeper integration with Renault and Mitsubishi. Ghosn added he had discussed the integration plans with Nissan\\'s CEO in September, a month before his arrest. He further said he wouldn\\'t flee if granted bail.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"].iloc[75]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04475602-ed14-461e-9622-cec3196c0e59",
   "metadata": {},
   "source": [
    "### Punctuation removal, stop word removal, loweing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d7112d-0833-4a41-ac42-3977786b2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d76b160-e60d-4570-ac7c-87c0db1db3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct_stop_words(sentence):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    punct_sentence = sentence.translate(translator)\n",
    "    \n",
    "    clean_words = []\n",
    "    for word in punct_sentence.split(' '):\n",
    "        if word not in stop_words:\n",
    "            clean_words.append(word.lower())\n",
    "\n",
    "    return ' '.join([word for word in clean_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fb5a50-9cfe-4b0c-9f02-aee4df3939c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"\"\"'Ousted Nissan Chairman Carlos Ghosn has said his arrest over alleged financial misconduct was led by \"plot and treason\" by the Japanese carmaker\\'s executives who opposed its deeper integration with Renault and Mitsubishi. Ghosn added he had discussed the integration plans with Nissan\\'s CEO in September, a month before his arrest. He further said he wouldn\\'t flee if granted bail.'\"\"\"\n",
    "\n",
    "clean_sentence = remove_punct_stop_words(sample_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad4f1cc6-fbda-4545-b2df-7f5a52c54f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ousted nissan chairman carlos ghosn said arrest alleged financial misconduct led plot treason japanese carmakers executives opposed deeper integration renault mitsubishi ghosn added discussed integration plans nissans ceo september month arrest he said wouldnt flee granted bail'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e526480-58ee-4b91-94ec-cda2acf754a8",
   "metadata": {},
   "source": [
    "### Punctuation removal, stop word removal, loweing \n",
    "### may not be helpful in this case as they cutdown the fluency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48690562-49fe-46ba-a556-71a35f1ef3a8",
   "metadata": {},
   "source": [
    "## We wil be movng without them\n",
    "## We will do tokenization and then Word embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b6129-93e8-4848-aa27-dbe69d2301c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"slauw87/bart_summarisation\")\n",
    "\n",
    "## Tokenization padding usin AutoTokenizer from Hugging face transformer model\n",
    "\n",
    "headlines = data[\"headlines\"].to_list()\n",
    "text = data[\"text\"].to_list()\n",
    "\n",
    "def tokenize_words(text, tokenizer):\n",
    "    \n",
    "    tokens = tokenizer(text, padding = True, truncation = True,\n",
    "                            return_tensors = \"pt\", max_length = 1024)\n",
    "    return tokens[\"input_ids\"], tokens[\"attention_mask\"]\n",
    "\n",
    "def create_tokens_attn_masks(text, tokenizer):\n",
    "    tokens_list, attn_masks_list = [], []\n",
    "    for line in text:\n",
    "        input_ids , attention_masks = tokenize_words(line, tokenizer)\n",
    "        tokens_list.append(input_ids)\n",
    "        attn_masks_list.append(attention_masks)\n",
    "\n",
    "    return tokens_list, attn_masks_list\n",
    "\n",
    "headlines_tokens, hl_attn_masks = create_tokens_attn_masks(headlines, tokenizer)\n",
    "text_tokens, text_attn_masks = create_tokens_attn_masks(text, tokenizer)\n",
    "\n",
    "headlines_tokens, hl_attn_masks = [], []\n",
    "for line in headlines:\n",
    "    input_ids , attention_masks = tokenize_words(line, tokenizer)\n",
    "    headlines_tokens.append(input_ids)\n",
    "    hl_attn_masks.append(attention_masks)\n",
    "\n",
    "text_tokens, text_attn_masks = [] , []\n",
    "for line in text:\n",
    "    input_ids , attention_masks = tokenize_words(line, tokenizer)\n",
    "    text_tokens.append(input_ids)\n",
    "    text_attn_masks.append(attention_masks)\n",
    "\n",
    "len(text_tokens)\n",
    "\n",
    "text_tokens[0].shape, text_tokens[20].shape, text_tokens[103].shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba97f8e-92c1-496c-8363-3522051d2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the Summarize text class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Summarize_text(Dataset):\n",
    "    def __init__(self, txt, summary, tokenizer, max_length = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.txt = txt\n",
    "        self.summary = summary\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.tokens_list, self.attn_masks_list = self.tokenize_words(self.txt)\n",
    "        self.smr_tokens_list, self.smr_attn_masks_list = self.tokenize_words(self.summary)\n",
    "\n",
    "\n",
    "    def tokenize_words(self, text):\n",
    "        tokens_list, attn_masks_list = [], []\n",
    "        for line in text:\n",
    "            tokens = tokenizer(line, padding = 'max_length', truncation = True,\n",
    "                                return_tensors = \"pt\", max_length = 4)\n",
    "            input_ids , attention_masks = tokens[\"input_ids\"], tokens[\"attention_mask\"]\n",
    "            tokens_list.append(input_ids.squeeze(0))\n",
    "            attn_masks_list.append(attention_masks.squeeze(0))\n",
    "        return tokens_list,  attn_masks_list\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\" : self.tokens_list[idx],\n",
    "            \"attention_mask\" : self.attn_masks_list[idx],\n",
    "            \"labels\" : self.smr_tokens_list[idx],\n",
    "            \"labels_attention_mask\" : self.smr_attn_masks_list[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d97e7c1c-7b19-4895-9a34-9862442736cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_V1(text, headlines, max_length = 4, batch_size = 4, stride =4, num_workers = 4):\n",
    "    dataset = Summarize_text(text,headlines,tokenizer, max_length = 4)\n",
    "    dataloader= DataLoader(dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers = num_workers\n",
    "                )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee7d8af0-bf15-49f6-980c-b1bfef747683",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = data[\"headlines\"].to_list()\n",
    "text = data[\"text\"].to_list()\n",
    "\n",
    "## Tokenization\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"slauw87/bart_summarisation\")\n",
    "dataloader = create_dataloader_V1(text, headlines, max_length = 4, batch_size = 4, stride =4, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dc02f1a-836a-4267-a6cf-0eaf5bc51d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dataloader)\n",
    "firstbatch= next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c7d7ca6-9266-46bb-b6eb-d51382c1c243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 42332,    41,     2],\n",
       "         [    0,   133,  5729,     2],\n",
       "         [    0, 36361,  5471,     2],\n",
       "         [    0,   250,   569,     2]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]]),\n",
       " 'labels': tensor([[    0,   176,     6,     2],\n",
       "         [    0,   448, 26772,     2],\n",
       "         [    0,   863,  2678,     2],\n",
       "         [    0, 12302,   661,     2]]),\n",
       " 'labels_attention_mask': tensor([[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2abb9083-2e54-4ccd-b44b-49faf08ec5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4104e+00, -7.8955e-01,  3.9243e-01,  1.6079e+00,  2.1909e+00,\n",
       "         -3.0261e-01,  4.3356e-01,  2.7988e-01,  3.4332e-01, -3.5139e+00],\n",
       "        [ 3.6605e-01,  1.7165e-01,  5.4576e-01, -1.4111e-01, -1.1584e+00,\n",
       "          5.4027e-02,  2.9665e+00,  1.3688e-01,  4.9501e-01,  1.5520e+00],\n",
       "        [ 2.0591e-01, -5.3120e-02,  1.2891e-01,  4.1605e-01, -4.1656e-02,\n",
       "          2.8797e-01,  1.6189e+00,  1.0940e+00,  5.5585e-01, -4.2801e-01],\n",
       "        [-4.2894e-01,  1.9008e+00, -9.8795e-01, -1.0188e+00,  9.3724e-01,\n",
       "         -2.7142e+00, -8.4535e-01,  7.1753e-01,  2.3240e-02,  4.9383e-01],\n",
       "        [ 2.0435e-03,  9.0907e-01, -1.9496e+00, -1.5696e+00, -4.7788e-01,\n",
       "         -8.8043e-02,  8.6036e-01, -6.0668e-01, -6.7618e-01,  1.3413e+00],\n",
       "        [ 8.6062e-01,  5.7633e-01,  6.3997e-01, -8.3114e-01, -2.2186e+00,\n",
       "          6.0251e-01,  2.3032e-01,  1.0184e+00, -1.1668e+00,  3.7657e-02],\n",
       "        [ 2.0591e-01, -5.3120e-02,  1.2891e-01,  4.1605e-01, -4.1656e-02,\n",
       "          2.8797e-01,  1.6189e+00,  1.0940e+00,  5.5585e-01, -4.2801e-01]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(torch.tensor([3, 2,4,5,6,12,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e3247-2f2d-4d37-9e9a-33d1560781ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162a572-79c8-470b-bd79-5c808e6d2956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2421542-daac-4768-8f77-800f53b28727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b54052-d19d-4afb-aa0b-980eab187189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c28b86-a031-4f07-be09-c36a211d72a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591cdf9-3ef1-4132-a58e-47176df341bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc86e60-978a-4a54-a516-a8267613b0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee799388-7fa9-41fa-8620-6fe7ec3a77e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801a912-9ae2-467e-8474-c90251037fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = text[0] + text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db5be96-f7c5-4c22-86da-30947fccb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3891c2-ab04-4698-a830-bebb7b9a1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782ed65-0224-4d22-a3df-a3ed39db2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6deff2e-50c2-477f-bb8a-3f5eb4e7130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "integers = tokenizer.encode(sample_text, allowed_special = {\"<|endoftext>\"})\n",
    "print(integers)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5907e7-3e66-4806-ad93-eba267efc167",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = tokenizer.decode(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd5eea-2631-485b-a5d3-8d46ea2af781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac749b59-497e-4071-99d0-c45f6394fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data set preparation\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids)-max_length,stride): ## Moving the words with stride lenght\n",
    "            input_chunk = token_ids[i : i+max_length]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "\n",
    "            target_chunk = token_ids[i+1 : i+max_length+1] ## predicting the next word\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "            \n",
    "            \n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe204d1-a842-4592-a74c-c42aa97bb29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating DataLoaders\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size =4, max_length = 256, \n",
    "                           stride = 128, shuffle = True, drop_last = True, \n",
    "                           num_workers = 0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8b156-b8df-4b9e-8866-e33d4003ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader_v1(sample_text, batch_size = 8, max_length =4, \n",
    "                                  stride =4, shuffle = False)\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "first_batch = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f500c-2c08-45fa-9483-5bc22616d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = tokenizer.encode(sample_text)\n",
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112df0e-a74b-42e0-b47e-a952eeebf53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([50, 2899, 615, 29576, 11, 281, 435, 4182, 385, 286, 510, 42731, 290, 2873, 2043, 12, 33, 338, 23842, 6118, 287, 10850, 4673, 290, 35941, 9345, 11, 373, 257, 21714, 11998, 23164, 379, \n",
    "     4806, 418, 893, 351, 2048, 642, 812, 286, 670, 1998, 13, 383, 1430, 290, 510, 42731, 338, 11470, 12, 16863, 3451, 1104, 4193, 683, 6801, 284, 257, 6060, 33374, 379, 9634])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabcff0-6777-4d82-afd6-9ac51f432aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499d1cc-dc06-453e-9db9-dfeb836b654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_batch = next(dataiter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb388c-b823-44cb-9f16-467249d76b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21099e-3ab7-4641-9c1f-5084877076ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch\n",
    "## One batch contains batch-size samples each of lenght = max_length \n",
    "## that gives total batch_size*max_length items in a batch\n",
    "## Stride "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cff169-7e96-46cb-b76e-53345e803caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_batch = next(dataiter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68b6fd-8aca-498a-ac3d-80858d01ce57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
